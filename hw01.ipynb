{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ex01_imp",
   "id": "3c6d8a7d5913a18c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re # import modułu Regular Expressions\n",
    "import requests  # import modułu do\n",
    "url = \"https://wolnelektury.pl/media/book/txt/pan-tadeusz.txt\" # wczytanie tekstu ze strony internetowej\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'  # ustawienie kodowania\n",
    "text = response.text\n",
    "\n",
    "text = text.lower() # konwersja na małe litery\n",
    "\n",
    "clear = \"\" # usunięcie znaków interpunkcyjnych\n",
    "for mark in text:\n",
    "    if mark not in [\".\",\"-\",\"!\",\"?\"]:\n",
    "        clear += mark\n",
    "\n",
    "words = re.findall(r\"\\w+\", clear, flags=re.UNICODE) # tokenizacja tekstu\n",
    "\n",
    "unique_words = set() # inicjalizacja zbioru unikalnych słów\n",
    "\n",
    "for word in words: # eliminacja duplikatów\n",
    "    unique_words.add(word)\n",
    "\n",
    "unique_list = list(unique_words) # konwersja zbioru na listę\n",
    "\n",
    "n = len(unique_list) # sortowanie według długości i alfabetycznie [sortowanie bąbelkowe]\n",
    "for i in range(n):\n",
    "    for j in range(0, n-i-1):\n",
    "        a = unique_list[j]\n",
    "        b = unique_list[j+1]\n",
    "\n",
    "        swap = False\n",
    "\n",
    "        if len(a) < len(b):\n",
    "            swap = True\n",
    "        elif len(a) == len(b) and a > b:\n",
    "            swap = True\n",
    "        if swap:\n",
    "            unique_list[j], unique_list[j+1] = unique_list[j+1], unique_list[j]\n",
    "\n",
    "top10 = unique_list[:10] # prezentacja wyników końcowych\n",
    "print(\"10 najdłuższych słów w »Panu Tadeuszu« (po usunięciu ., -, !, ?):\")\n",
    "for i in range(len(top10)):\n",
    "    print(f\"{i + 1}. {top10[i]} (długość: {len(top10[i])})\")"
   ],
   "id": "1403f7b7535cc981",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ex01_func",
   "id": "19023504df681d76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re # import modułu Regular Expressions\n",
    "\n",
    "PUNCT_TO_REMOVE = \".-!?,\"  # zdefiniowanie stałej definiujacej znaki interpukcyjne do usunięcia\n",
    "\n",
    "def read_text(url: str) -> str:  # pobieranie tekstu ze strony internetowej\n",
    "    response = requests.get(url)\n",
    "    response.encoding = 'utf-8'\n",
    "    return response.text\n",
    "\n",
    "def normalize(text: str) -> str: # zamiana na małe litery i usunięcie wybranych znaków interpunkcyjnych\n",
    "    text_lower = text.lower()\n",
    "    text_clean = text_lower.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "    return text_clean\n",
    "\n",
    "def to_words(text: str) -> list[str]: # zamiana tekstu na listę słów\n",
    "    return re.findall(r\"\\w+\", text, flags=re.UNICODE)\n",
    "\n",
    "def unique(words: list[str]) -> list[str]: # utworzenie listy unikalnych słów\n",
    "    return list(set(words))\n",
    "\n",
    "def sort_words_by_length(words: list[str], n: int = 10) -> list[str]: # zwracanie n najdłuższych słów, przy remisie sortując alfabetycznie\n",
    "    return sorted(words, key=lambda w: (-len(w), w))[:n]\n",
    "\n",
    "def compose(*functions): # złożenie funkcji [1. wczytaj_tekst → 2. normalizuj_tekst → 3. zamień_na_słowa → 4. unikalne_słowa → 5. sortuj_słowa_po_długosci]\n",
    "    def inner(arg):\n",
    "        result = arg\n",
    "        for func in reversed(functions):\n",
    "            result = func(result)\n",
    "        return result\n",
    "    return inner\n",
    "\n",
    "def pipeline(data, *functions): # etap sekwencyjnego przetwrzania\n",
    "    result = data\n",
    "    for func in functions:\n",
    "        result = func(result)\n",
    "    return result\n",
    "\n",
    "def format_results(words: list[str]) -> str: # format wyników do czytelnej postaci\n",
    "    lines = [\"10 najdłuższych słów w »Panu Tadeuszu« (po usunięciu ., -, !, ?, ,):\"]\n",
    "    for i, w in enumerate(words, start=1):\n",
    "        lines.append(f\"{i}. {w} (długość: {len(w)})\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def main_functional_compose():\n",
    "    process_text = compose(\n",
    "        lambda words: sort_words_by_length(words, n=10),\n",
    "        unique,\n",
    "        to_words,\n",
    "        normalize,\n",
    "        read_text\n",
    "    )\n",
    "    top10 = process_text(\"https://wolnelektury.pl/media/book/txt/pan-tadeusz.txt\")\n",
    "    print(format_results(top10))\n",
    "\n",
    "if __name__ == \"__main__\": # wykonanie głównej funkcji\n",
    "    main_functional_compose()"
   ],
   "id": "a57813a6fbf61300",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ex02_imp",
   "id": "8a894820c4964a0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_text(url: str) -> str: # definicja funkcji odczytu tekstu ze strony internetowej\n",
    "    response = requests.get(url)\n",
    "    response.encoding = 'utf-8'\n",
    "    return response.text\n",
    "\n",
    "def find_most_common_words_imperative(text: str, n: int = 10, min_length: int = 6) -> list[tuple[str, int]]: # definicja funkcji znajdującej najczęściej występującej słowa w tekście\n",
    "\n",
    "    text_lower = text.lower() # konwersja na małe litery\n",
    "\n",
    "    punct_to_remove = \".-!?,\"  # filtrowanie znaków interpunkcyjnych\n",
    "    cleaned_text = \"\"\n",
    "    for char in text_lower:\n",
    "        if char not in punct_to_remove:\n",
    "            cleaned_text += char\n",
    "\n",
    "    all_words = []  # tokenizacja tekstu\n",
    "    current_word = \"\"\n",
    "    for char in cleaned_text:\n",
    "        if char == \" \" or char == \"\\n\" or char == \"\\t\":\n",
    "            if current_word != \"\":\n",
    "                all_words.append(current_word)\n",
    "                current_word = \"\"\n",
    "        else:\n",
    "            current_word += char\n",
    "    if current_word != \"\":\n",
    "        all_words.append(current_word)\n",
    "\n",
    "    words = []  # filtrowanie krótkich słów\n",
    "    for word in all_words:\n",
    "        if len(word) > min_length:\n",
    "            words.append(word)\n",
    "\n",
    "    word_counts = {} #  # zliczanie wystąpień słów\n",
    "    for word in words:\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += 1\n",
    "        else:\n",
    "            word_counts[word] = 1\n",
    "\n",
    "    word_list = [] # konwersja słownika na listę krotek\n",
    "    for word in word_counts:\n",
    "        word_list.append((word, word_counts[word]))\n",
    "\n",
    "\n",
    "    for i in range(len(word_list)): # sortowanie malejąco według liczby wystąpień (bubble sort)\n",
    "        for j in range(i + 1, len(word_list)):\n",
    "            if word_list[j][1] > word_list[i][1]:\n",
    "                temp = word_list[i]\n",
    "                word_list[i] = word_list[j]\n",
    "                word_list[j] = temp\n",
    "\n",
    "\n",
    "    result = [] # zwrócenie top n wyników\n",
    "    limit = n\n",
    "    if len(word_list) < n:\n",
    "        limit = len(word_list)\n",
    "\n",
    "    for i in range(limit):\n",
    "        result.append(word_list[i])\n",
    "\n",
    "    return result\n",
    "\n",
    "def main(): # definicja funkcji głównej\n",
    "    print(\"Analiza najczęstszych słów w »Panu Tadeuszu«\")\n",
    "    print(\"(po usunięciu znaków: . - ! ? ,)\")\n",
    "    print(\"(tylko słowa dłuższe niż 6 znaki)\\n\")\n",
    "\n",
    "    text = read_text(\"https://wolnelektury.pl/media/book/txt/pan-tadeusz.txt\")\n",
    "\n",
    "    top_10 = find_most_common_words_imperative(text, n=10, min_length=6)\n",
    "\n",
    "    print(\"10 najczęstszych słów:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for i in range(len(top_10)):\n",
    "        word, count = top_10[i]\n",
    "        print(f\"{i + 1:2d}. {word:15s} - {count:4d} wystąpień\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": # wykonanie funkcji głównej\n",
    "    main()"
   ],
   "id": "1e71de398165fb83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ex02_func",
   "id": "9154491ef8adb7de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "def read_text(url: str) -> str: # definicja funkcji read text\n",
    "    response = requests.get(url)\n",
    "    response.encoding = 'utf-8'\n",
    "    return response.text\n",
    "\n",
    "def find_most_common_words_functional(text: str, n: int = 10, min_length: int = 6) -> list[tuple[str, int]]: # definicja funkcji find_most_common_words_functional\n",
    "\n",
    "    punct_to_remove = \".-!?,\" # deklaracja zmiennej punct_to_remove\n",
    "\n",
    "    return Counter( # przetwarzanie tekstu i zwracanie najczęstszych słów\n",
    "        filter(\n",
    "            lambda word: len(word) > min_length,\n",
    "            \"\".join(\n",
    "                map(lambda char: \"\" if char in punct_to_remove else char, text.lower())\n",
    "            ).split()\n",
    "        )\n",
    "    ).most_common(n)\n",
    "\n",
    "\n",
    "def main(): # główna funkcja\n",
    "    print(\"Analiza najczęstszych słów w »Panu Tadeuszu«\")\n",
    "    print(\"(po usunięciu znaków: . - ! ? ,)\")\n",
    "    print(\"(tylko słowa dłuższe niż 6 znaki)\\n\")\n",
    "\n",
    "    text = read_text(\"https://wolnelektury.pl/media/book/txt/pan-tadeusz.txt\")\n",
    "\n",
    "    top_10 = find_most_common_words_functional(text, n=10, min_length=6)\n",
    "\n",
    "    print(\"10 najczęstszych słów:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for i, (word, count) in enumerate(top_10, 1):\n",
    "        print(f\"{i:2d}. {word:15s} - {count:4d} wystąpień\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": # wykonanie głównej funkcji\n",
    "    main()"
   ],
   "id": "be6bb88ed894a32f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ex03_imp",
   "id": "b75ca32808ed57c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_word_length_histogram_imperative(text: str, max_length: int = 10) -> dict[int, int]: # definicja funkcji wyznaczającej długość słów w tekscie\n",
    "\n",
    "    punct_to_remove = \".-!?,\" # usunięcie znaków interpunkcyjnych\n",
    "    cleaned_text = \"\"\n",
    "\n",
    "    for char in text.lower():\n",
    "        if char not in punct_to_remove:\n",
    "            cleaned_text += char\n",
    "        else:\n",
    "            cleaned_text += \" \"\n",
    "\n",
    "\n",
    "    words = cleaned_text.split() # podział na słowa\n",
    "\n",
    "\n",
    "    histogram = {}    # zliczanie długości słów do max długości\n",
    "\n",
    "    for word in words:\n",
    "        length = len(word)\n",
    "        if 0 < length <= max_length:\n",
    "            if length in histogram:\n",
    "                histogram[length] += 1\n",
    "            else:\n",
    "                histogram[length] = 1\n",
    "\n",
    "    return histogram\n",
    "\n",
    "\n",
    "def read_text(url: str) -> str: # wczytanie tekstu ze strony internetowej\n",
    "    response = requests.get(url)\n",
    "    response.encoding = 'utf-8'\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def print_histogram_horizontal(histogram: dict[int, int], max_length: int = 10) -> None: # zdefiniowanie funkcji histogram\n",
    "\n",
    "    print(\"Histogram długości słów w »Panu Tadeuszu«\")\n",
    "    print(\"(po usunięciu znaków: . - ! ? ,)\")\n",
    "    print(\"(słowa o długości 1-10 liter)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    if not histogram:\n",
    "        print(\"Brak danych do wyświetlenia\")\n",
    "        return\n",
    "\n",
    "    max_count = max(histogram.values()) # zanlezienie maksymalnej liczby wystąpień\n",
    "\n",
    "    chart_height = 20 #wysokość wykresu (liczba wierszy)\n",
    "\n",
    "    scale = max_count / chart_height if max_count > 0 else 1 # obliczanie skali\n",
    "\n",
    "    for row in range(chart_height, 0, -1): # rozpoczęcie rysowania wykresu od gory do dołu\n",
    "\n",
    "        threshold = row * scale # wartość progowa dla wiersza\n",
    "\n",
    "        print(f\"{int(threshold):5d} |\", end=\"\") # wyświetlenie wartości na osi Y\n",
    "\n",
    "        for length in range(1, max_length + 1): # dla każdej długości słowa (1-10)\n",
    "            count = histogram.get(length, 0)\n",
    "\n",
    "            if count >= threshold: # warunek liczba wystąpień przekracza próg, rysuj słupek\n",
    "                print(\"  ███\", end=\"\")\n",
    "            else:\n",
    "                print(\"     \", end=\"\")\n",
    "\n",
    "        print()  # nowa linia\n",
    "\n",
    "    print(\"      \" + \"─\" * (max_length * 5)) # oś X (linia pozioma)\n",
    "\n",
    "    print(\"      \", end=\"\")  # etykieta osi X (długości słów)\n",
    "    for length in range(1, max_length + 1):\n",
    "        print(f\"  {length:2d} \", end=\"\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Dokładne wartości:\") # legenda z dokładnymi wartościami\n",
    "    print(\"-\" * 80)\n",
    "    for length in range(1, max_length + 1):\n",
    "        count = histogram.get(length, 0)\n",
    "        print(f\"Długość {length:2d}: {count:6d} wystąpień\")\n",
    "\n",
    "\n",
    "def main(): # funkcja główna\n",
    "    max_length = 10\n",
    "\n",
    "    text = read_text(\"https://wolnelektury.pl/media/book/txt/pan-tadeusz.txt\") # wczytanie tekstu ze strony\n",
    "\n",
    "    histogram = calculate_word_length_histogram_imperative(text, max_length) # wczytanie histogramu\n",
    "\n",
    "    print_histogram_horizontal(histogram, max_length) # wyświetlenie wyników (histogram poziomy)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80) # dodatkowe statystyki\n",
    "    print(\"Statystyki (dla słów 1-10 liter):\")\n",
    "    total_words = sum(histogram.values())\n",
    "    print(f\"Łączna liczba słów (1-10 liter): {total_words}\")\n",
    "\n",
    "    if histogram: # najczęstsza długość słowa\n",
    "\n",
    "        most_common_length = max(histogram.keys(), key=lambda k: histogram[k])\n",
    "        print(f\"Najczęstsza długość słowa: {most_common_length} ({histogram[most_common_length]} wystąpień)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": # wykonanie funkcji głównej\n",
    "    main()"
   ],
   "id": "8d65570105227abf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ex03_func",
   "id": "9dcecf3f8a488af1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter # importuje klasę counter z modułu collections\n",
    "\n",
    "def read_text(url: str) -> str: #  funkcja wczytania tekstu ze strony internetowej\n",
    "    response = requests.get(url)\n",
    "    response.encoding = 'utf-8'\n",
    "    return response.text\n",
    "\n",
    "def calculate_word_length_histogram_functional(text: str, max_length: int = 10) -> dict[int, int]: # wyznaczenie histogramu długości słów w tekście\n",
    "\n",
    "    punct_to_remove = \".-!?,\" # blok kodu mający na celu usunięcie interpunkcji, podział,filtracje i zliczanie\n",
    "\n",
    "    return dict(\n",
    "        Counter(\n",
    "            map(\n",
    "                len,  # mapowanie słów na ich długości\n",
    "                filter(\n",
    "                    lambda word: 0 < len(word) <= max_length,  # filtracja długości\n",
    "                    \"\".join(\n",
    "                        map(\n",
    "                            lambda char: \" \" if char in punct_to_remove else char,\n",
    "                            text.lower()\n",
    "                        )\n",
    "                    ).split()\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def print_histogram_horizontal(histogram: dict[int, int], max_length: int = 10) -> None: # wyświetlenie histogramu w formie poziomej\n",
    "    print(\"Histogram długości słów w »Panu Tadeuszu«\")\n",
    "    print(\"(po usunięciu znaków: . - ! ? ,)\")\n",
    "    print(\"(słowa o długości 1-10 liter)\")\n",
    "    print(\"(podejście funkcyjne)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    if not histogram:\n",
    "        print(\"Brak danych do wyświetlenia\")\n",
    "        return\n",
    "\n",
    "    max_count = max(histogram.values()) if histogram else 0 # znalezienie maksymalnej liczby wystąpień\n",
    "\n",
    "    chart_height = 20 # wysokość wykresu (liczba wierszy)\n",
    "\n",
    "    scale = max_count / chart_height if max_count > 0 else 1 # obliczanie skali histogramu\n",
    "\n",
    "    rows = range(chart_height, 0, -1) # generowanie wierszy wykresu\n",
    "\n",
    "    for row in rows:\n",
    "        threshold = row * scale\n",
    "        print(f\"{int(threshold):5d} |\", end=\"\")\n",
    "\n",
    "        # funkcyjne generowanie słupków dla każdej długości\n",
    "        bars = map(\n",
    "            lambda length: \"  ███\" if histogram.get(length, 0) >= threshold else \"     \",\n",
    "            range(1, max_length + 1)\n",
    "        )\n",
    "\n",
    "        print(\"\".join(bars))\n",
    "\n",
    "    print(\"      \" + \"─\" * (max_length * 5)) # oś X\n",
    "\n",
    "    print(\"      \" + \"\".join(map(lambda l: f\"  {l:2d} \", range(1, max_length + 1))))\n",
    "    print() # etykiety osi X\n",
    "\n",
    "    print(\"Dokładne wartości:\") # legenda z dokładnymi wartościami\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    list(map(\n",
    "        lambda length: print(f\"Długość {length:2d}: {histogram.get(length, 0):6d} wystąpień\"),\n",
    "        range(1, max_length + 1) # wyświetlenie wartości\n",
    "    ))\n",
    "\n",
    "\n",
    "def main():\n",
    "    max_length = 10\n",
    "\n",
    "    # wczytanie tekstu\n",
    "    text = read_text(\"https://wolnelektury.pl/media/book/txt/pan-tadeusz.txt\")\n",
    "\n",
    "    # wyznaczenie histogramu\n",
    "    histogram = calculate_word_length_histogram_functional(text, max_length)\n",
    "\n",
    "    # wyświetlenie wyników\n",
    "    print_histogram_horizontal(histogram, max_length)\n",
    "\n",
    "    # dodatkowe statystyki\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Statystyki (dla słów 1-10 liter):\")\n",
    "\n",
    "    total_words = sum(histogram.values())\n",
    "    print(f\"Łączna liczba słów (1-10 liter): {total_words}\")\n",
    "\n",
    "    if histogram:\n",
    "        most_common_length = max(histogram.keys(), key=lambda k: histogram[k])\n",
    "        print(f\"Najczęstsza długość słowa: {most_common_length} ({histogram[most_common_length]} wystąpień)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": # # wykonanie funkcji głównej\n",
    "    main()"
   ],
   "id": "6e43bf0bd6b2735e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
